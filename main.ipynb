{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is about merging 3 dataset Energy, Productions, and Fermate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.getDataset import getEntireDataset\n",
    "from scripts.plots import plot\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.options.mode.copy_on_write = False\n",
    "\n",
    "dataset = getEntireDataset(306, 2023, 1)\n",
    "\n",
    "plot(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I iterate for every machine to get the data from the 3 datasets and merge them into one dataset, removing the ones that are not useful for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT1 ~ Now we can check for all the dataset and see what we can do with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import plot\n",
    "from scripts.getDataset import getEntireDataset, forEveryMachine, cleanDataset\n",
    "import pandas as pd\n",
    "\n",
    "DEBUG = False\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.options.mode.copy_on_write = False\n",
    "\n",
    "most_interesting = []\n",
    "\n",
    "def fn(machineId, year, month):\n",
    "    dataset = getEntireDataset(machineId, year, month, False)\n",
    "\n",
    "    if dataset.empty:\n",
    "        return\n",
    "\n",
    "    if dataset[\"EnergyConsumption\"].dropna().eq(0).all():\n",
    "        if DEBUG:\n",
    "            print(\"Skipping as EnergyConsumption is all 0\")\n",
    "        return\n",
    "    if dataset[\"Fermate\"].dropna().eq(0).all():\n",
    "        if DEBUG:\n",
    "            print(\"Skipping as Fermate is all 0\")\n",
    "        return\n",
    "\n",
    "    EC_na = dataset[\"EnergyConsumption\"].isna().sum()\n",
    "    EC_len = dataset[\"EnergyConsumption\"].shape[0]\n",
    "\n",
    "    ST_na = dataset[\"Fermate\"].isna().sum()\n",
    "    ST_len = dataset[\"Fermate\"].shape[0]\n",
    "\n",
    "    energyRate = EC_na/ EC_len\n",
    "    stopsRate = ST_na/ ST_len\n",
    "\n",
    "    if energyRate > 0.5 or stopsRate > 0.5:\n",
    "        if DEBUG:\n",
    "            print(\"Skipping as too many NaN values\")\n",
    "            print(\"\\tEnergy Rate:\", energyRate)\n",
    "            print(\"\\tStops Rate:\", stopsRate)\n",
    "        return\n",
    "\n",
    "    most_interesting.append((cleanDataset(dataset), machineId, year, month))\n",
    "\n",
    "forEveryMachine(fn)\n",
    "\n",
    "print(\"\\n\\n\\nThe most interesting are the followings:\")\n",
    "for dataset, machineId, year, month in most_interesting:\n",
    "    dataset.to_csv(f\"dataset/results/it1/id-{machineId}_{year}-{month}.csv\", index=False)\n",
    "    print(f\"- Machine {machineId} - {year}/{month}\")\n",
    "\n",
    "for dataset, machineId, year, month in most_interesting:\n",
    "    plot(dataset, machineId, year, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT2 ~ It took 20 minutes to compute everything but now I want to look at the lifetime of the machines and see if I can find something interesting, merging the data into one file for machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.getSingleDataset.utils import getCleanDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = [p for p in os.listdir(\"dataset/results/it1\") if p.endswith(\".csv\")]\n",
    "\n",
    "compete_dataset = {}\n",
    "\n",
    "for path in files:\n",
    "    # dataset.to_csv(f\"dataset/results/it1/id-{machineId}_{year}-{month}.csv\")\n",
    "\n",
    "    splitted_filename = [p.split(\"-\") for p in path.replace(\".csv\", \"\").split(\"_\")]\n",
    "\n",
    "    machineId = int(splitted_filename[0][1])\n",
    "    year = int(splitted_filename[1][0])\n",
    "    month = int(splitted_filename[1][1])\n",
    "\n",
    "    d = getCleanDataset(f\"dataset/results/it1/id-{machineId}_{year}-{month}.csv\")\n",
    "\n",
    "    # plot(d)\n",
    "    value = [d]\n",
    "\n",
    "    if machineId in compete_dataset:\n",
    "        old_data = compete_dataset.get(machineId)\n",
    "        \n",
    "        for old in old_data:\n",
    "            value.append(old)\n",
    "        \n",
    "\n",
    "    compete_dataset.update({machineId: value})\n",
    "\n",
    "for machineId in compete_dataset.keys():\n",
    "    d = pd.concat(compete_dataset.get(machineId))\n",
    "\n",
    "    d.to_csv(f\"dataset/results/it2/id-{machineId}.csv\", mode=\"w\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT3 ~ Now I use the pearson correlation to see the correlation between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.getSingleDataset.utils import getCleanDataset\n",
    "from scipy import stats\n",
    "from scripts.plots import plot\n",
    "\n",
    "files = [p for p in os.listdir(\"dataset/results/it2\") if p.endswith(\".csv\")]\n",
    "\n",
    "STR = \"\\t\\t{:0.2f}\\n\\t\\tP-Value:{:0.2f}\"\n",
    "\n",
    "def is_correlation_usable(data):\n",
    "    computing_data = data.dropna()\n",
    "\n",
    "    print(f\"Machine {machineId}\")\n",
    "    # Correlazione tra Energia e Produzioni\n",
    "    energy_productions_corr, energy_productions_pvalue = stats.pearsonr(\n",
    "        computing_data[\"EnergyConsumption\"], computing_data[\"Productions\"]\n",
    "    )\n",
    "    print(\"\\tCorrelation between Energy Consumption and Productions\")\n",
    "    print(STR.format(energy_productions_corr, energy_productions_pvalue))\n",
    "    if energy_productions_pvalue <= 0.05:\n",
    "        print(\"\\t\\tSignificant\")\n",
    "\n",
    "    # Correlazione tra Energia e Fermate\n",
    "    energy_stops_corr, energy_stops_pvalue = stats.pearsonr(\n",
    "        computing_data[\"EnergyConsumption\"], computing_data[\"Fermate\"]\n",
    "    )\n",
    "    print(\"\\tCorrelation between Energy Consumption and Stops\")\n",
    "    print(STR.format(energy_stops_corr, energy_stops_pvalue))\n",
    "    if energy_stops_pvalue <= 0.05:\n",
    "        print(\"\\t\\tSignificant\")\n",
    "\n",
    "    # Correlazione tra Produzioni e Fermate\n",
    "    productions_stops_corr, productions_stops_pvalue = stats.pearsonr(\n",
    "        computing_data[\"Productions\"], computing_data[\"Fermate\"]\n",
    "    )\n",
    "    print(\"\\tCorrelation between Productions and Stops\")\n",
    "    print(STR.format(productions_stops_corr, productions_stops_pvalue))\n",
    "    if productions_stops_pvalue <= 0.05:\n",
    "        print(\"\\t\\tSignificant\")\n",
    "\n",
    "    return (\n",
    "        energy_productions_pvalue <= 0.05\n",
    "        or energy_stops_pvalue <= 0.05\n",
    "        or productions_stops_pvalue <= 0.05\n",
    "    )\n",
    "\n",
    "dfs = [(int(file.replace(\".csv\", \"\").split(\"-\")[1]), getCleanDataset(f\"dataset/results/it2/{file}\")) for file in files]\n",
    "\n",
    "usable_datasets = [df for df in dfs if is_correlation_usable(df[1])]\n",
    "\n",
    "print(\"Usable datasets: \", len(usable_datasets))\n",
    "\n",
    "tot = 0\n",
    "for machineId, d in usable_datasets:\n",
    "    d.to_csv(f\"dataset/results/it3/id-{machineId}.csv\", mode=\"w\", index=False)\n",
    "    tot += d.shape[0]\n",
    "    print(\"- Machine\", machineId)\n",
    "print(\"Total:\", tot)\n",
    "\n",
    "for machineId, d in usable_datasets:\n",
    "    plot(d, machineId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to use a linear model to try to predict the lifetime of the machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "files = [p for p in os.listdir(\"dataset/results/it3\") if p.endswith(\".csv\")]\n",
    "\n",
    "full_data = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(f\"dataset/results/it3/{file}\")\n",
    "    data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"-\")[1])\n",
    "    # data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"_\")[0].split(\"-\")[1])\n",
    "\n",
    "    full_data = pd.concat([full_data, data])\n",
    "\n",
    "total = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    tot = len(files)\n",
    "    train_len = int(tot * 0.6)\n",
    "\n",
    "    shuffled = shuffle(full_data.dropna())\n",
    "    train_data = shuffled[: train_len]\n",
    "    test_data = shuffled[: tot - train_len]\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(train_data[[\"EnergyConsumption\", \"Productions\"]], train_data[\"Fermate\"])\n",
    "\n",
    "    # Valutare il modello utilizzando i dati di test\n",
    "    prediction = model.predict(test_data[[\"EnergyConsumption\", \"Productions\"]])\n",
    "    res = ((prediction - test_data[\"Fermate\"]) ** 2).mean()\n",
    "    \n",
    "    total += res\n",
    "\n",
    "print(\"MeanSquareError:\", total/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanSquareError: 2.1524654335599256\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_files = [p for p in os.listdir(\"dataset/results/it3\") if p.endswith(\".csv\")]\n",
    "train_data = pd.DataFrame()\n",
    "for file in train_files:\n",
    "    data = pd.read_csv(f\"dataset/results/it3/{file}\")\n",
    "    data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"-\")[1])\n",
    "    # data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"_\")[0].split(\"-\")[1])\n",
    "\n",
    "    train_data = pd.concat([train_data, data])\n",
    "\n",
    "\n",
    "test_files = [p for p in os.listdir(\"dataset/results/it1\") if p.endswith(\".csv\")]\n",
    "test_data = pd.DataFrame()\n",
    "for file in test_files:\n",
    "    data = pd.read_csv(f\"dataset/results/it1/{file}\")\n",
    "    data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"-\")[1])\n",
    "    # data[\"MachineId\"] = int(file.replace(\".csv\", \"\").split(\"_\")[0].split(\"-\")[1])\n",
    "\n",
    "    test_data = pd.concat([test_data, data])\n",
    "\n",
    "total = 0\n",
    "\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "for i in range(1000):\n",
    "    # train_len = int(len(train_files) * 0.6)\n",
    "\n",
    "    # shuffled = shuffle(train_data.dropna())\n",
    "    # test_data = shuffled[: tot - train_len]\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(train_data[[\"EnergyConsumption\", \"Productions\"]], train_data[\"Fermate\"])\n",
    "\n",
    "    # Valutare il modello utilizzando i dati di test\n",
    "    prediction = model.predict(test_data[[\"EnergyConsumption\", \"Productions\"]])\n",
    "    res = ((prediction - test_data[\"Fermate\"]) ** 2).mean()\n",
    "\n",
    "    total += res\n",
    "\n",
    "print(\"MeanSquareError:\", total / 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
